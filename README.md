# a-series-of-dropout

根据实验发现：

如果使用log_sigma2作为参数优化，Hierarchical跟Sparse会很快的稀疏化(Hierarchical更快)，导致Hierarchical不能正确分类(10%)，Sparse则收敛很慢(48%)

第一个为Hierarchical，第二个为Sparse，取第一层conv和最后一层fc的log_alpha

![59c6878a-bcd9-4965-9243-699dc2527341](D:\download\tp\59c6878a-bcd9-4965-9243-699dc2527341.svg)

![d5105f69-f144-4c3c-b130-0b7ae8e7683c](D:\download\tp\d5105f69-f144-4c3c-b130-0b7ae8e7683c.svg)

故改为使用log_alpha为参数，在cifar10上，Hierarchical的稀疏能力没有Sparse好

![8740d293-7c4b-4b75-89d6-15a47dfea578](D:\download\tp\8740d293-7c4b-4b75-89d6-15a47dfea578.svg)![f054c30a-366a-460c-bd19-0d40ff31ca41](D:\download\tp\f054c30a-366a-460c-bd19-0d40ff31ca41.svg)

VDA：在最后一个conv后和在第一个fc前差不多

VDB：new更好，区别在于尺寸一个是对B（new，类似于做了局部重采样），一个是对W(维度更高)，但new会直接就log_alpha下降了，没有稀疏性了呀！或许是由于使用的网络太小了？

![d8d63303-2f27-4354-b6b3-305872b72b01](D:\download\tp\d8d63303-2f27-4354-b6b3-305872b72b01.svg)

实验结果：

A: (第一行)在fc前 (第二行)在conv后

B: (第一行)对W (第二行)对B

batchsize=1000 adam默认 lr=0.001 epoch 100

|                          | Scale(1.0)                 | Scale(1.5)                | Scale(2.0)                |
| ------------------------ | -------------------------- | ------------------------- | ------------------------- |
| Bernoulli                | 56.32/55.67    56.23/54.96 | 57.22/56.11   56.55/56.21 | 58.05/57.13   58.21/57.63 |
| GaussianS                | 49.33/48.99                | 50.93/49.92               | 52.21/50.75               |
| GaussianW                | 56.57/56.35                | 58.34/57.52               | 58.52/57.60               |
| NoDropout                | 58.53/57.09                | 58.49/55.51               | 59.61/56.87               |
| VariationalA             | 55.85/55.31                | 54.63/54.58               | 54.88/54.41               |
| VariationalB             | 56.45/56.45                | 57.98/56.59               | 58.30/56.93               |
| VariationalSparseb       | 56.16/55.32                | 55.38/54.91               | 56.72/56.10               |
| VariationalHierarchicalb | 55.41/55.41   61.60/60.68  | 56.62/56.20               | 55.85/54.97               |
| VariationalHierarchicalA | **60.80/59.96**            | **60.73/59.95**           | 60.01**/60.01**           |
| VariationalHierarchicalB | 56.70/56.19                | 57.07/56.26               | 56.30/55.99               |

  

new:

|                          | Scale(1.0)                | Scale(1.5)                | Scale(2.0)                |
| ------------------------ | ------------------------- | ------------------------- | ------------------------- |
| GaussianS                | 49.53/48.64   48.90/48.39 | 51.69/50.53   51.48/51.13 | 51.05/50.22   51.68/50.78 |
| GaussianW                | 53.86/53.63               | 56.51/55.75               | 57.39/57.02               |
| VariationalA             | 55.42/55.00   58.34/57.57 | 54.32/53.80   55.94/55.12 | 55.41/54.34   55.03/53.80 |
| VariationalB             | 59.8/59.64                | 62.10/**62.10**           | 61.88/60.54               |
| VariationalHierarchicalA | 59.78/59.78   60.25/59.69 | 60.59/60.50   59.48/58.64 | 61.22/60.47   59.14/58.04 |
| VariationalHierarchicalB | **61.77/61.08**           | **62.14**/61.58           | **62.71/61.30**           |
| VariationalSparseA       | 59.97/59.40   60.17/60.12 | 60.25/60.01   59.60/59.23 | 59.88/59.47   60.24/58.51 |
| VariationalSparseB       | **62.38/61.34**           | **62.56/62.29**           | **63.28/62.38**           |

 

 